{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PIwMHgUvGaVw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('Customers.csv')\n",
        "print(\"Customers Data Loaded: \", customers.shape)\n",
        "\n",
        "products = pd.read_csv('Products.csv')\n",
        "print(\"Products Data Loaded: \", products.shape)\n",
        "\n",
        "transactions = pd.read_csv('Transactions.csv')\n",
        "print(\"Transactions Data Loaded: \", transactions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQRVSYo-HWw2",
        "outputId": "9093ed45-900b-44b2-8562-9dd3fb4ef4b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers Data Loaded:  (200, 4)\n",
            "Products Data Loaded:  (100, 4)\n",
            "Transactions Data Loaded:  (1000, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "print(\"Missing Values in Customers:\", customers.isnull().sum())\n",
        "print(\"Missing Values in Products:\", products.isnull().sum())\n",
        "print(\"Missing Values in Transactions:\", transactions.isnull().sum())\n",
        "\n",
        "# Dropping rows with missing values\n",
        "customers.dropna(inplace=True)\n",
        "products.dropna(inplace=True)\n",
        "transactions.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldSGNM45HaLX",
        "outputId": "e08fdddb-c56b-4731-8d08-00fa65a6fa27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values in Customers: CustomerID      0\n",
            "CustomerName    0\n",
            "Region          0\n",
            "SignupDate      0\n",
            "dtype: int64\n",
            "Missing Values in Products: ProductID      0\n",
            "ProductName    0\n",
            "Category       0\n",
            "Price          0\n",
            "dtype: int64\n",
            "Missing Values in Transactions: TransactionID      0\n",
            "CustomerID         0\n",
            "ProductID          0\n",
            "TransactionDate    0\n",
            "Quantity           0\n",
            "TotalValue         0\n",
            "Price              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert SignupDate and TransactionDate to datetime\n",
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
        "\n",
        "# Ensure numerical columns are correctly typed\n",
        "transactions['Quantity'] = transactions['Quantity'].astype(int)\n",
        "transactions['TotalValue'] = transactions['TotalValue'].astype(float)\n",
        "products['Price'] = products['Price'].astype(float)"
      ],
      "metadata": {
        "id": "vTca3KByHdQO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 1. Merge Transactions with Products to get Category and Price\n",
        "transactions_products = transactions.merge(products, on='ProductID', how='left')\n",
        "\n",
        "# 2. Compute total spend per customer\n",
        "customer_spend = transactions.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
        "customer_spend.rename(columns={'TotalValue': 'TotalSpend'}, inplace=True)\n",
        "\n",
        "# 3. Compute average transaction value per customer\n",
        "customer_avg_trans = transactions.groupby('CustomerID')['TotalValue'].mean().reset_index()\n",
        "customer_avg_trans.rename(columns={'TotalValue': 'AvgTransactionValue'}, inplace=True)\n",
        "\n",
        "# 4. Compute number of transactions per customer\n",
        "customer_num_trans = transactions.groupby('CustomerID')['TransactionID'].nunique().reset_index()\n",
        "customer_num_trans.rename(columns={'TransactionID': 'NumTransactions'}, inplace=True)\n",
        "\n",
        "# 5. Determine favorite category per customer\n",
        "favorite_category = transactions_products.groupby(['CustomerID', 'Category'])['Quantity'].sum().reset_index()\n",
        "favorite_category = favorite_category.sort_values(['CustomerID', 'Quantity'], ascending=[True, False])\n",
        "favorite_category = favorite_category.drop_duplicates(subset=['CustomerID'], keep='first')\n",
        "favorite_category = favorite_category[['CustomerID', 'Category']].rename(columns={'Category': 'FavoriteCategory'})\n",
        "\n",
        "# 6. Merge all customer features\n",
        "customer_features = customers.merge(customer_spend, on='CustomerID', how='left') \\\n",
        "                             .merge(customer_avg_trans, on='CustomerID', how='left') \\\n",
        "                             .merge(customer_num_trans, on='CustomerID', how='left') \\\n",
        "                             .merge(favorite_category, on='CustomerID', how='left')\n",
        "\n",
        "# 7. Fill any missing values resulting from merges\n",
        "customer_features['TotalSpend'] = customer_features['TotalSpend'].fillna(0)\n",
        "customer_features['AvgTransactionValue'] = customer_features['AvgTransactionValue'].fillna(0)\n",
        "customer_features['NumTransactions'] = customer_features['NumTransactions'].fillna(0)\n",
        "customer_features['FavoriteCategory'] = customer_features['FavoriteCategory'].fillna('Unknown')\n",
        "\n",
        "# 8. Feature: Tenure in days from SignupDate to latest TransactionDate\n",
        "latest_date = transactions['TransactionDate'].max()\n",
        "customer_features['TenureDays'] = (latest_date - customer_features['SignupDate']).dt.days\n",
        "\n",
        "# 9. Distinct Categories Purchased\n",
        "distinct_categories = transactions_products.groupby('CustomerID')['Category'].nunique().reset_index()\n",
        "distinct_categories.rename(columns={'Category': 'DistinctCategories'}, inplace=True)\n",
        "\n",
        "# 10. Recency: Days since last transaction\n",
        "last_transaction = transactions.groupby('CustomerID')['TransactionDate'].max().reset_index()\n",
        "last_transaction['Recency'] = (latest_date - last_transaction['TransactionDate']).dt.days\n",
        "last_transaction = last_transaction[['CustomerID', 'Recency']]\n",
        "\n",
        "# 11. Merge these features\n",
        "customer_features = customer_features.merge(distinct_categories, on='CustomerID', how='left') \\\n",
        "                                     .merge(last_transaction, on='CustomerID', how='left')\n",
        "\n",
        "# 12. Fill missing values\n",
        "customer_features['DistinctCategories'] = customer_features['DistinctCategories'].fillna(0)\n",
        "\n",
        "# 13. Fill missing Recency values\n",
        "# If a customer has no transactions, Recency can be set to their full tenure\n",
        "customer_features['Recency'] = customer_features['Recency'].fillna(customer_features['TenureDays'])\n",
        "\n",
        "# 14. Now, drop SignupDate and CustomerName as they are not needed for similarity\n",
        "customer_features = customer_features.drop(['CustomerName', 'SignupDate'], axis=1)\n",
        "\n",
        "print(customer_features.head())\n",
        "print(customer_features.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3wL28UEHgMw",
        "outputId": "1551882e-203a-48e1-85fb-1eb33586d44c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CustomerID         Region  TotalSpend  AvgTransactionValue  NumTransactions  \\\n",
            "0      C0001  South America     3354.52              670.904              5.0   \n",
            "1      C0002           Asia     1862.74              465.685              4.0   \n",
            "2      C0003  South America     2725.38              681.345              4.0   \n",
            "3      C0004  South America     5354.88              669.360              8.0   \n",
            "4      C0005           Asia     2034.24              678.080              3.0   \n",
            "\n",
            "  FavoriteCategory  TenureDays  DistinctCategories  Recency  \n",
            "0      Electronics         902                 3.0     55.0  \n",
            "1       Home Decor        1049                 2.0     25.0  \n",
            "2       Home Decor         296                 3.0    125.0  \n",
            "3       Home Decor         811                 3.0      4.0  \n",
            "4      Electronics         866                 2.0     54.0  \n",
            "Index(['CustomerID', 'Region', 'TotalSpend', 'AvgTransactionValue',\n",
            "       'NumTransactions', 'FavoriteCategory', 'TenureDays',\n",
            "       'DistinctCategories', 'Recency'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Defining feature columns\n",
        "numerical_features = ['TotalSpend', 'AvgTransactionValue', 'NumTransactions',\n",
        "                      'TenureDays', 'DistinctCategories', 'Recency']\n",
        "categorical_features = ['Region', 'FavoriteCategory']\n",
        "\n",
        "# Defining ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fitting and transforming the data\n",
        "feature_matrix = preprocessor.fit_transform(customer_features)\n",
        "\n",
        "print(f\"Type of feature_matrix: {type(feature_matrix)}\")\n",
        "\n",
        "if hasattr(feature_matrix, \"toarray\"):\n",
        "    feature_matrix = feature_matrix.toarray()\n",
        "    print(\"Converted sparse matrix to dense array.\")\n",
        "else:\n",
        "    print(\"feature_matrix is already a dense NumPy array.\")\n",
        "\n",
        "# Get CustomerIDs\n",
        "customer_ids = customer_features['CustomerID'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXzdvfTpIEKd",
        "outputId": "46de00aa-0d73-4893-caf0-4da6354237e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of feature_matrix: <class 'numpy.ndarray'>\n",
            "feature_matrix is already a dense NumPy array.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Computing cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(feature_matrix)\n",
        "\n",
        "# Converting to DataFrame for easier handling\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=customer_ids, columns=customer_ids)"
      ],
      "metadata": {
        "id": "ikwEzVr_IXpE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort CustomerIDs to get first 20 (assuming they are sorted alphanumerically)\n",
        "sorted_customers = sorted(customer_ids)\n",
        "first_20_customers = sorted_customers[:20]\n",
        "print(\"First 20 Customers:\", first_20_customers)\n",
        "\n",
        "lookalike_dict = {}\n",
        "\n",
        "for customer in first_20_customers:\n",
        "    sim_scores = similarity_df.loc[customer].copy()\n",
        "    sim_scores[customer] = -1\n",
        "\n",
        "    # Get top 3 customers with highest similarity\n",
        "    top_3 = sim_scores.sort_values(ascending=False).head(3)\n",
        "\n",
        "    lookalike_dict[customer] = list(zip(top_3.index, top_3.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrpZ4YLjIeFB",
        "outputId": "c6788304-ba30-4305-95bd-2cdfaaae1368"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 20 Customers: ['C0001', 'C0002', 'C0003', 'C0004', 'C0005', 'C0006', 'C0007', 'C0008', 'C0009', 'C0010', 'C0011', 'C0012', 'C0013', 'C0014', 'C0015', 'C0016', 'C0017', 'C0018', 'C0019', 'C0020']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lookalike_data = []\n",
        "\n",
        "for cust_id, lookalikes in lookalike_dict.items():\n",
        "    for lookalike_id, score in lookalikes:\n",
        "        lookalike_data.append({\n",
        "            'CustomerID': cust_id,\n",
        "            'LookalikeID': lookalike_id,\n",
        "            'SimilarityScore': score\n",
        "        })\n",
        "\n",
        "lookalike_df = pd.DataFrame(lookalike_data)\n",
        "\n",
        "lookalike_pivot = lookalike_df.groupby('CustomerID').apply(\n",
        "    lambda x: list(zip(x['LookalikeID'], x['SimilarityScore']))\n",
        ").reset_index(name='Lookalikes')\n",
        "\n",
        "lookalike_pivot.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "print(\"Lookalike.csv generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ0NdwRmIgsx",
        "outputId": "b0d02cb0-bdb0-47ca-f239-0c13b8acfc2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike.csv generated successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-84bc4af1174d>:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  lookalike_pivot = lookalike_df.groupby('CustomerID').apply(\n"
          ]
        }
      ]
    }
  ]
}